{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Co-training_3C.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2JNuUEhPUzxPMEXxc85bD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssvadla/Sharing/blob/main/Co_training_3C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkbUcWRPHvjJ"
      },
      "source": [
        "def training(unlabel_1,train,i,j):\n",
        "    train_size = len(train)\n",
        "    train_size_list.append(train_size)\n",
        "    i_list.append(i)\n",
        "    j_list.append(j)\n",
        "    print(\"length of the UL received\",len(unlabel_1))\n",
        "    \n",
        "   \n",
        "    import pandas as pd\n",
        "    from sklearn.model_selection import KFold\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "\n",
        "    from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "#     train1 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data1.csv')\n",
        "#     train2 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data2.csv')\n",
        "#     train3 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data3.csv')\n",
        "#     train4 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data4.csv')\n",
        "#     train5 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data5.csv')\n",
        "#     train6 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data6.csv')\n",
        "#     train7 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data7.csv')\n",
        "#     train8 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data8.csv')\n",
        "#     train9 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data9.csv')\n",
        "#     train10 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data10.csv')\n",
        "#     train_highKappa = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data_highkappa.csv')\n",
        "\n",
        "#     train1.head()\n",
        "#     train = train1\n",
        "#     train_list = [train2,train3,train4,train5,train6,train7,train8,train9,train10,train_highKappa]\n",
        "#     for i in train_list:\n",
        "#         #print(i)\n",
        "#         train = train.append(i)\n",
        "\n",
        "#     #unlabel_size = unlabel_size\n",
        "#     #Threshold=Threshold\n",
        "#     train.sort_values(\"Sentence\", inplace = True)\n",
        "#     print(len(train))\n",
        "\n",
        "#     train = train.drop_duplicates(subset =\"Sentence\")\n",
        "\n",
        "#     train['Target'].unique()\n",
        "\n",
        "\n",
        "#     train['Target']=train['Target'].replace(['Others'],'Invalid')\n",
        "#     train['Target'].unique()\n",
        "#     print(len(train))\n",
        "\n",
        "\n",
        "\n",
        "    #cleaning\n",
        "    import nltk\n",
        "    import re\n",
        "    import string\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('wordnet')\n",
        "    stopword=nltk.corpus.stopwords.words('english')\n",
        "    from nltk.stem import WordNetLemmatizer\n",
        "    wl= WordNetLemmatizer()\n",
        "\n",
        "    def clean_text(text):\n",
        "      text=\"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "      tokens = re.split('\\W+',text)\n",
        "      text = [wl.lemmatize(word) for word in tokens if word not in stopword]\n",
        "      return text\n",
        "\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "    tfidf_vect = TfidfVectorizer(analyzer = clean_text)\n",
        "    #X_tfidf = tfidf_vect.fit_transform(train['Sentence'])\n",
        "    X_tfidf = tfidf_vect.fit_transform(train['text'])\n",
        "    print(X_tfidf.shape)\n",
        "\n",
        "    test = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\test_data.csv')\n",
        "\n",
        "    test['Target']=test['Target'].replace(['Others'],'Invalid')\n",
        "    test['Sentence'] = test['Sentence'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "    test['Sentence'] = test['Sentence'].str.replace('[^\\w\\s]','')\n",
        "    from nltk.corpus import stopwords\n",
        "    words = stopwords.words('english')\n",
        "    test['Sentence'] = test['Sentence'].apply(lambda x: \" \".join(x for x in x.split() if x not in words))\n",
        "    t_p = tfidf_vect.transform(test['Sentence'])\n",
        "\n",
        "    import lightgbm as lgb\n",
        "    from sklearn import svm\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    classifier_rf = RandomForestClassifier(n_estimators = 350, criterion = 'gini', max_features = 'auto', random_state = 42)\n",
        "    classifier_lgb = lgb.LGBMClassifier()\n",
        "    classifier_svm = svm.LinearSVC(multi_class='ovr',class_weight='balanced')\n",
        "\n",
        "    #train = train.rename(columns={'Sentence':'text'})\n",
        "    train.head()\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "    from sklearn.datasets import make_classification\n",
        "\n",
        "    from sklearn.pipeline import make_pipeline\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import average_precision_score\n",
        "    from sklearn.metrics import precision_score\n",
        "    from sklearn.metrics import recall_score\n",
        "    from sklearn.metrics import f1_score\n",
        "    from sklearn.metrics import cohen_kappa_score\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "\n",
        "    #X, y = make_classification(random_state=1)\n",
        "\n",
        "    X_train, x_val, Y_train, y_val = train_test_split(X_tfidf,train['Target'],test_size=0.20,random_state=42)\n",
        "\n",
        "    X_train_whole = X_tfidf\n",
        "    Y_train_whole = train['Target']\n",
        "    #X_train_whole, x_val_whole, Y_train_whole, y_val_whole = train_test_split(X_tfidf,train['Target'],test_size=0.1,random_state=42)\n",
        "\n",
        "    \n",
        "    classifier_rf.fit(X_train, Y_train)\n",
        "    classifier_lgb.fit(X_train, Y_train)\n",
        "    classifier_svm.fit(X_train, Y_train)\n",
        "\n",
        "    val_pred_rf = classifier_rf.predict(x_val)\n",
        "    val_pred_lgb = classifier_lgb.predict(x_val)\n",
        "    val_pred_svm = classifier_svm.predict(x_val)\n",
        "\n",
        "    Accuracy_score_rf = accuracy_score(y_val,val_pred_rf)\n",
        "    print(\"Accuracy_score_rf \",Accuracy_score_rf)\n",
        "    Accuracy_score_lgb = accuracy_score(y_val,val_pred_lgb)\n",
        "    print(\"Accuracy_score_lgb \",Accuracy_score_lgb)\n",
        "    Accuracy_score_svm = accuracy_score(y_val,val_pred_svm)\n",
        "    print(\"Accuracy_score_svm \",Accuracy_score_svm)\n",
        "\n",
        "\n",
        "    classification_report_test_rf = classification_report(y_val,val_pred_rf)\n",
        "    print(\"classification report rf\",classification_report_test_rf)\n",
        "    classification_report_test_lgb = classification_report(y_val,val_pred_lgb)\n",
        "    print(\"classification report lgb\",classification_report_test_lgb)\n",
        "    classification_report_test_svm = classification_report(y_val,val_pred_svm)\n",
        "    print(\"classification report svm \",classification_report_test_svm)\n",
        "    \n",
        "    cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
        "    cross_valid_rf = cross_val_score(classifier_rf,x_val ,y_val, scoring = 'f1_weighted', cv=cv, n_jobs=-1).mean()\n",
        "    print(\"cross validation score RF\",cross_valid_rf)\n",
        "    cross_valid_lgb = cross_val_score(classifier_lgb,x_val ,y_val, scoring = 'f1_weighted', cv=cv, n_jobs=-1).mean()\n",
        "    print(\"cross validation score LGB\",cross_valid_lgb)\n",
        "    cross_valid_svm = cross_val_score(classifier_svm,x_val ,y_val, scoring = 'f1_weighted', cv=cv, n_jobs=-1).mean()\n",
        "    print(\"cross validation score SVM\",cross_valid_svm)\n",
        "\n",
        "\n",
        "    f1_score_rf = f1_score(y_val,val_pred_rf,average='weighted')\n",
        "    print(\" f1 score test rf \",f1_score_rf )\n",
        "    f1_score_lgb = f1_score(y_val,val_pred_lgb, average='weighted')\n",
        "    print(\" f1 score test lgb \",f1_score_lgb )\n",
        "    f1_score_svm = f1_score(y_val,val_pred_svm, average='weighted')\n",
        "    print(\" f1 score test svm \",f1_score_svm )\n",
        "\n",
        "    if (Accuracy_score_rf > Accuracy_score_lgb) and (Accuracy_score_rf > Accuracy_score_svm):\n",
        "      B = classifier_rf\n",
        "    elif (Accuracy_score_svm > Accuracy_score_lgb) and (Accuracy_score_svm > Accuracy_score_rf):\n",
        "      B = classifier_svm\n",
        "    else:\n",
        "      B = classifier_lgb\n",
        "\n",
        "\n",
        "    B.fit(X_train_whole,Y_train_whole)\n",
        "    test_pred = B.predict(t_p)\n",
        "    accuracy_test = accuracy_score(test['Target'],test_pred)\n",
        "    print('Accuracy test data', accuracy_test)\n",
        "    f1_score_test = f1_score(test['Target'],test_pred, average='weighted')\n",
        "    print(\" f1 score test \",f1_score_test )\n",
        "    \n",
        "    f1_score_test_list.append(f1_score_test)\n",
        "    \n",
        "    classification_report_test_data = classification_report(test['Target'],test_pred)\n",
        "    print(\"classification report \",classification_report_test_data)\n",
        "    \n",
        "    # class_x_un1 = tfidf_vect.transform(unlabel_1['text'])\n",
        "    # pseudo_pred = B.predict(class_x_un1)\n",
        "\n",
        "    class_x_un1 = tfidf_vect.transform(unlabel_1['text'])\n",
        "\n",
        "    class_pred_unlabel_1 = B.predict(class_x_un1)\n",
        "    unlabel_1['Target']=class_pred_unlabel_1\n",
        "    frame_1 = [train,unlabel_1]\n",
        "    train_1 = pd.concat(frame_1)\n",
        "    \n",
        "    print(len(train_1))\n",
        "    \n",
        "    \n",
        "    \n",
        "    with open(r'C:\\Users\\iia\\Documents\\Supriya\\Co_training_results_3C\\unlabel_test.txt', 'a') as writefile:\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" Co-training results \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" train_size \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(str(train_size))\n",
        "        writefile.write(\" Accuracy_score_rf = \")\n",
        "        writefile.write(str(Accuracy_score_rf))\n",
        "        writefile.write(\" Accuracy_score_lgb = \")\n",
        "        writefile.write(str(Accuracy_score_lgb))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" Accuracy_score_svm = \")\n",
        "        writefile.write(str(Accuracy_score_svm))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" classification_report_test_rf = \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(str(classification_report_test_rf))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" classification_report_test_lgb = \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(str(classification_report_test_lgb))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" classification_report_test_svm = \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(str(classification_report_test_svm))\n",
        "        writefile.write(\"\\n\")\n",
        "      \n",
        "        writefile.write(\" cross_valid_rf = \")\n",
        "        writefile.write(str(cross_valid_rf))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" cross_valid_lgb = \")\n",
        "        writefile.write(str(cross_valid_lgb))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" cross_valid_svm = \")\n",
        "        writefile.write(str(cross_valid_svm))\n",
        "        writefile.write(\"\\n\")\n",
        "        \n",
        "        writefile.write(\" f1_score_rf = \")\n",
        "        writefile.write(str(f1_score_rf))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" f1_score_lgb = \")\n",
        "        writefile.write(str(f1_score_lgb))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" f1_score_svm = \")\n",
        "        writefile.write(str(f1_score_svm))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" Results on test data \")\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" f1_score_test = \")\n",
        "        writefile.write(str(f1_score_test))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" classifier selected = \")\n",
        "        writefile.write(str(B))\n",
        "        writefile.write(\"\\n\")\n",
        "        writefile.write(\" classification_report_test_data = \")\n",
        "        writefile.write(str(classification_report_test_data))\n",
        "        writefile.write(\"\\n\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    return train_1,train_size_list,f1_score_test_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # print('Validation Accuracy_score: %f' % Accuracy_score)\n",
        "    # test_pred = classifier.predict(t_p)\n",
        "    # acc_test = accuracy_score(test_pred,test['Target'])\n",
        "    # print('Accuracy test data', acc_test)\n",
        "    # matrix = confusion_matrix(y_pred, y_val)\n",
        "    # print(matrix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okqw6tYFH1Xx"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcHbFL_gH7Mr"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopword=nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl= WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwFto_a-H_ha"
      },
      "source": [
        "unlabel = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Unlabeled_data.csv')\n",
        "unlabel.head()\n",
        "\n",
        "\n",
        "del unlabel['Complete']\n",
        "\n",
        "del unlabel['Unnamed: 0']\n",
        "\n",
        "unlabel.head()\n",
        "\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "unlabel['text'] = unlabel['text'].str.replace('[^\\w\\s]','')\n",
        "from nltk.corpus import stopwords\n",
        "words = stopwords.words('english')\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in words))\n",
        "\n",
        "\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: TextBlob(x).words)\n",
        "unlabel['text'] = unlabel['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))\n",
        "\n",
        "unlabel.head()\n",
        "\n",
        "\n",
        "len(unlabel)\n",
        "\n",
        "\n",
        "\n",
        "# unlabel_1 = unlabel.loc[:100]\n",
        "# unlabel_1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpNng9BAIC8K"
      },
      "source": [
        "train1 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data1.csv')\n",
        "train2 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data2.csv')\n",
        "train3 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data3.csv')\n",
        "train4 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data4.csv')\n",
        "train5 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data5.csv')\n",
        "train6 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data6.csv')\n",
        "train7 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data7.csv')\n",
        "train8 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data8.csv')\n",
        "train9 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data9.csv')\n",
        "train10 = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data10.csv')\n",
        "train_highKappa = pd.read_csv(r'C:\\Users\\iia\\Documents\\Supriya\\Train_data\\train_data_highkappa.csv')\n",
        "\n",
        "train1.head()\n",
        "train = train1\n",
        "train_list = [train2,train3,train4,train5,train6,train7,train8,train9,train10,train_highKappa]\n",
        "for i in train_list:\n",
        "    #print(i)\n",
        "    train = train.append(i)\n",
        "\n",
        "#unlabel_size = unlabel_size\n",
        "#Threshold=Threshold\n",
        "train.sort_values(\"Sentence\", inplace = True)\n",
        "print(len(train))\n",
        "\n",
        "train = train.drop_duplicates(subset =\"Sentence\")\n",
        "\n",
        "train['Target'].unique()\n",
        "\n",
        "\n",
        "train['Target']=train['Target'].replace(['Others'],'Invalid')\n",
        "train['Target'].unique()\n",
        "print(len(train))\n",
        "train = train.rename(columns={'Sentence':'text'})\n",
        "all_Data_train_size = len(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sVdhkwpIGS6"
      },
      "source": [
        "length_list = range(1000,100000,5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NUH2vopILJF"
      },
      "source": [
        "j=0\n",
        "iteration = 0\n",
        "i_list = []\n",
        "j_list = []\n",
        "f1_score_test_list = []\n",
        "train_size_list =[]\n",
        "\n",
        "for i in length_list:\n",
        "  print(\"iteration \",iteration)\n",
        "  print(i)\n",
        "  print(j)\n",
        "  unlabel_chunk = unlabel[j:i]\n",
        "  train,op_train_size_list,op_f1_score_test_list = training(unlabel_chunk,train,i,j)\n",
        "  j=i\n",
        "  iteration = iteration + 1\n",
        "  print(\"length\",len(unlabel_chunk))\n",
        "    \n",
        "with open(r'C:\\Users\\iia\\Documents\\Supriya\\Co_training_results_3C\\unlabel_test_variables.txt', 'a') as writefile:\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\" Co-training results \")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\" train size \")\n",
        "    writefile.write(str(all_Data_train_size))\n",
        "    writefile.write(\"\\n\")\n",
        "#     writefile.write(\"op_unlabel_size\")\n",
        "#     writefile.write(\"\\n\")\n",
        "#     writefile.write(str(op_unlabel_size))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_train_size_list\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(str(op_train_size_list))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_f1_score_test_list\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(str(op_f1_score_test_list))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n88BRkXPIOXm"
      },
      "source": [
        "with open(r'C:\\Users\\iia\\Documents\\Supriya\\Co_training_results\\unlabel_test_variables.txt', 'a') as writefile:\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\" Co-training results \")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\" train size \")\n",
        "    writefile.write(str(all_Data_train_size))\n",
        "    writefile.write(\"\\n\")\n",
        "#     writefile.write(\"op_unlabel_size\")\n",
        "#     writefile.write(\"\\n\")\n",
        "#     writefile.write(str(op_unlabel_size))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_train_size_list\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(str(op_train_size_list))\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(\"op_f1_score_test_list\")\n",
        "    writefile.write(\"\\n\")\n",
        "    writefile.write(str(op_f1_score_test_list))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}